# -*- coding: utf-8 -*-
"""koelectra_checkipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1isTanmE-qBBYuiU1-TbIySEPNCX28uSK
"""

from transformers import AutoModelForSequenceClassification, AutoTokenizer

# 모델을 불러올 경로
model_load_path = '/content/drive/MyDrive/DSL/DSL_modeling_project/'

# 모델 불러오기
tokenizer = AutoTokenizer.from_pretrained("daekeun-ml/koelectra-small-v3-nsmc")
#model = AutoModelForSequenceClassification.from_pretrained("daekeun-ml/koelectra-small-v3-nsmc")
model = AutoModelForSequenceClassification.from_pretrained(model_load_path)

import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_excel('/content/drive/MyDrive/DSL/DSL_modeling_project/test_맞춤법.xlsx')
df.rename(columns={'긍부정': 'Label'}, inplace=True)
s =df['Sentence'][46]
print(s)

import json
import sys
import logging
import torch
from torch import nn
from transformers import ElectraConfig
from transformers import ElectraModel, AutoTokenizer, ElectraTokenizer, ElectraForSequenceClassification

logging.basicConfig(
    level=logging.INFO,
    format='[{%(filename)s:%(lineno)d} %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(filename='tmp.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

max_seq_length = 128
classes = ['Neg', 'Pos']

tokenizer = AutoTokenizer.from_pretrained("daekeun-ml/koelectra-small-v3-nsmc")
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def predict_fn(transformed_inputs, model):
    predicted_classes = []

    for data in transformed_inputs:
        data = data.to(device)
        output = model(**data)

        softmax_fn = nn.Softmax(dim=1)
        softmax_output = softmax_fn(output[0])
        _, prediction = torch.max(softmax_output, dim=1)

        predicted_class_idx = prediction.item()
        predicted_class = classes[predicted_class_idx]
        score = softmax_output[0][predicted_class_idx]
        logger.info("predicted_class: {}".format(predicted_class))

        prediction_dict = {}
        prediction_dict["predicted_label"] = predicted_class
        prediction_dict['score'] = score.cpu().detach().numpy().tolist()

        jsonline = json.dumps(prediction_dict)
        logger.info("jsonline: {}".format(jsonline))
        predicted_classes.append(jsonline)

    predicted_classes_jsonlines = "\n".join(predicted_classes)
    return predicted_classes_jsonlines


def output_fn(outputs, accept="application/jsonlines"):
    return outputs, accept

def input_fn(input_data, content_type="text/plain"):
    # 입력 데이터를 토큰화하여 반환
    encode_plus_token = tokenizer.encode_plus(
        input_data,
        max_length=max_seq_length,
        add_special_tokens=True,
        return_token_type_ids=False,
        padding="max_length",
        return_attention_mask=True,
        return_tensors="pt",
        truncation=True,
    )
    return [encode_plus_token]

def model_fn(model_path=None):
    ####
    # If you have your own trained model
    # Huggingface pre-trained model: 'monologg/koelectra-small-v3-discriminator'
    ####
    #config = ElectraConfig.from_json_file(f'{model_path}/config.json')
    #model = ElectraForSequenceClassification.from_pretrained(f'{model_path}/model.pth', config=config)

    # Download model from the Huggingface hub
    model = AutoModelForSequenceClassification.from_pretrained(model_load_path)
    model.to(device)
    return model

s =df['Sentence'][47]
print(s)

model = model_fn()
transformed_inputs = input_fn(s)
predicted_classes_jsonlines = predict_fn(transformed_inputs, model)
model_outputs = output_fn(predicted_classes_jsonlines)
print(model_outputs[0])

data = json.loads(model_outputs[0])

# 'predicted_label' 키의 값을 추출
predicted_label = data['predicted_label']
predicted_label

import pandas as pd
electdf2 = pd.DataFrame(columns=['판별라벨', '진짜라벨', '내용'])

for i in range(len(df)):
    transformed_inputs = input_fn(df['Sentence'][i])
    predicted_classes_jsonlines = predict_fn(transformed_inputs, model)
    model_outputs = output_fn(predicted_classes_jsonlines)
    data = json.loads(model_outputs[0])
    predicted_label = data['predicted_label']

    # 새로운 행을 생성하여 값을 할당합니다.
    electdf2.loc[i, '판별라벨'] = predicted_label
    electdf2.loc[i, '진짜라벨'] = df['Label'][i]
    electdf2.loc[i, '내용'] = df['Sentence'][i]

# '판별라벨'과 '진짜라벨' 열을 문자열로 변환합니다.
electdf2['판별라벨'] = electdf2['판별라벨'].astype(str)
electdf2['진짜라벨'] = electdf2['진짜라벨'].astype(str)

electdf2['판별라벨'] = electdf2['판별라벨'].map({'Pos': '1', 'Neg': '0'})

# '판별라벨'과 '진짜라벨' 열이 같은 경우를 세어봅니다.
same_count = electdf2[electdf2['판별라벨'] == electdf2['진짜라벨']].shape[0]

print("두 열의 값이 같은 경우의 수:", same_count / len(df))

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# 예시 데이터프레임
# electdf2 = pd.DataFrame({'판별라벨': [0, 1, 0, 1], '진짜라벨': [0, 1, 1, 0]})

# 위양성, 위음성, 진짜 양성, 진짜 음성 계산
true_positive = ((electdf2['판별라벨'] == '1') & (electdf2['진짜라벨'] == '1')).sum()
false_positive = ((electdf2['판별라벨'] == '1') & (electdf2['진짜라벨'] == '0')).sum()
true_negative = ((electdf2['판별라벨'] == '0') & (electdf2['진짜라벨'] == '0')).sum()
false_negative = ((electdf2['판별라벨'] == '0') & (electdf2['진짜라벨'] == '1')).sum()

# 2x2 행렬 생성
confusion_matrix = pd.DataFrame([[true_negative, false_positive], [false_negative, true_positive]],
                                index=['Real 0', 'Real 1'],
                                columns=['Predicted 0', 'Predicted 1'])

# plot 생성
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='d', cbar=False, annot_kws={"size": 14})
plt.title('Electra Confusion Matrix', fontsize=16)
plt.xlabel('Predicted Label', fontsize=14)
plt.ylabel('True Label', fontsize=14)
plt.show()